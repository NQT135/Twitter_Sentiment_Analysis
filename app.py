import streamlit as st
import joblib
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(page_title="Twitter Sentiment Analysis", page_icon="üê¶")

# --- H√ÄM X·ª¨ L√ù TEXT (GI·ªÆ NGUY√äN NH∆Ø C≈®) ---
def clean_text(text):
    # ƒê·∫£m b·∫£o logic n√†y GI·ªêNG H·ªÜT file train
    ps = PorterStemmer()
    text = re.sub('[^a-zA-Z]', ' ', text)
    text = text.lower()
    text = text.split()
    
    # D√πng whitelist nh∆∞ ƒë√£ b√†n
    all_stopwords = stopwords.words('english')
    whitelist = ["n't", "not", "no", "nor"]
    final_stopwords = [word for word in all_stopwords if word not in whitelist]
    
    text = [ps.stem(word) for word in text if not word in set(final_stopwords)]
    text = ' '.join(text)
    return text

# --- H√ÄM T·∫¢I VECTORIZER & SCALER (CH·ªà T·∫¢I 1 L·∫¶N) ---
@st.cache_resource
def load_preprocessors():
    try:
        cv = joblib.load('vectorizer.pkl')
        sc = joblib.load('scaler.pkl')
        return cv, sc
    except FileNotFoundError:
        st.error("Thi·∫øu file vectorizer.pkl ho·∫∑c scaler.pkl")
        return None, None

# --- GIAO DI·ªÜN CH√çNH ---
st.title("üê¶ Multi-Model Sentiment Analysis")

# 1. T·∫£i b·ªô x·ª≠ l√Ω chung
cv, sc = load_preprocessors()

# 2. MENU CH·ªåN MODEL (SIDEBAR)
st.sidebar.header("üîß Control Panel")
model_options = {
    "Logistic Regression": "model_LogisticRegression.pkl",
    "Random Forest": "model_RandomForest.pkl",
    "Decision Tree": "model_DecisionTree.pkl",
    "Support Vector Machine (SVM)": "model_SVM.pkl",
    "XGBoost": "model_XGBoost.pkl"
}

# T·∫°o Dropdown ƒë·ªÉ ch·ªçn
selected_model_name = st.sidebar.selectbox("Ch·ªçn thu·∫≠t to√°n:", list(model_options.keys()))

# L·∫•y t√™n file t∆∞∆°ng ·ª©ng
selected_model_file = model_options[selected_model_name]

# 3. T·∫¢I MODEL ƒê∆Ø·ª¢C CH·ªåN
try:
    model = joblib.load(selected_model_file)
    st.sidebar.success(f"ƒê√£ t·∫£i: {selected_model_name}")
except FileNotFoundError:
    st.error(f"Kh√¥ng t√¨m th·∫•y file {selected_model_file}. H√£y ch·∫°y file train l·∫°i!")
    model = None

# --- PH·∫¶N D·ª∞ ƒêO√ÅN ---
st.write(f"ƒêang s·ª≠ d·ª•ng m√¥ h√¨nh: **{selected_model_name}**")
user_input = st.text_area("Nh·∫≠p n·ªôi dung Tweet t·∫°i ƒë√¢y:", height=100)

if st.button("Analyze Sentiment"):
    if user_input.strip() == "":
        st.warning("Vui l√≤ng nh·∫≠p n·ªôi dung!")
    elif model is None or cv is None:
        st.error("L·ªói: Ch∆∞a t·∫£i ƒë∆∞·ª£c model ho·∫∑c b·ªô x·ª≠ l√Ω.")
    else:
        # X·ª≠ l√Ω
        processed_text = clean_text(user_input)
        vectorized_text = cv.transform([processed_text]).toarray()
        scaled_text = sc.transform(vectorized_text)
        
        # D·ª± ƒëo√°n
        prediction = model.predict(scaled_text)
        
        # Hi·ªÉn th·ªã k·∫øt qu·∫£
        st.divider()
        col1, col2 = st.columns(2)
        
        with col1:
            st.info("Input Text")
            st.write(f"_{user_input}_")
            
        with col2:
            st.info("Prediction Result")
            # Logic hi·ªÉn th·ªã (Ki·ªÉm tra l·∫°i dataset c·ªßa b·∫°n 0 hay 1 l√† t√≠ch c·ª±c nh√©)
            # N·∫øu dataset c·ªßa b·∫°n l√† 0: T·ªët, 1: X·∫•u (Hate Speech) th√¨ s·ª≠a l·∫°i d√≤ng d∆∞·ªõi
            if prediction[0] == 1:
                st.markdown("### üò° Negative / Hate")
            else:
                st.markdown("### üòä Positive / Normal")

# --- TH√îNG TIN NH√ìM ---
st.sidebar.divider()
st.sidebar.text("Group: [Insert Group No]")